AI coding/usage policy:
AI generated code is forbidden in the project core, it is only allowed in the periphery
(i.e. dependent features that are useless without the core, esp. code implementing supporting/convenience features).

The reason are two issues with AI generated code:
- generated code could be a copyright/license-breach of existing code from other projects published under stricter licenses like GPL
- the GrGen-core should be under LGPL-license, so that improvements have to be published/returned back (this requires human authorship)

In detail/what is considered to be the project core:

AI generated code is forbidden in:
- the implementation of the model, rule/computations, and embedded control languages, i.e. in the compiler
- the implementation of the control language, i.e. in the sequences interpreter
- the implementation of the existing shell-language-constructs, i.e. in the GrShell interpreter
  (a base execution environment for file mapping should be available as LGPL version,
   the some holds for base debugging support with console printing)
- some execution environment features
   in the interface and supporting code for basic/rudimentary graph visualization (the mapping to a graph viewer library or app)
   in the interface and supporting code for graph persistence, including the SQLite persistence provider (its ORM-mapping)
- cornerstone compilation and esp. execution tests highlighting the execution semantics of the model, rule/computations, and control language
  (simple examples explaining the language constructs/features, achieving a basic coverage of the language definitions)

AI generated code is allowed for:
- all GUI features on top of the basic graph visualization,
  esp. GUI-debugging-features visualizing the model, rules, and sequences (and similar debugging visualizations/development support)
- new shell features (that are not strictly required to use the core or extensions of the other GrGen languages)
  (new persistence providers or backends, i.e. new dlls only linking against the LGPL core)
- test code, esp. unit tests (/internal implementation tests), but also non-cornerstone compiler(/syntax) tests, and non-cornerstone execution(/semantic) tests
  (to achieve a high test coverage protecting from regressions)

Consequences / specific rules: 
- AI generated code should be contained in separate files as far as possible
  so code extensions in the core parts required by AI features must be supplied by a human programmer,
  (e.g. hooks/interfaces for null/mock objects that are then replaced by the AI with their normal functionality)
  so refactorings changing non-AI code by AI bots have to be limited to the non-core parts,
  and should/must be marked as such in case of non-negligible changes
  (also new code from AI agents should/must be marked, AI generated files must come without the normal copyright header)
- AI generated code must by reviewed by a human developer
- if you are concerned about the first issue with AI generated code mentioned at the top of the file,
  you should keep your hands of using the GUI debugger or the libGrShell (at least dedicated features) at API level

This is a quite strict policy which might change in the future upon legal clarifications (or AI improvements; but keeping the core hand-written and LGPL protected is intended, even if the development process is slower).
(What's the difference between an AI agent refactoring and a normal IDE refactoring? Or AI-based vs non-AI auto-completions/code-generating-wizards? Interactive helpers supplied with IDEs instead of full-scope generation from specification?)

AI generated code is likely to be considered to be in the public domain, similar to the SQLite used in implementing the persistent graph, or the code generated by the parser generators, or the code generated by GrGen itself.
This is well acceptable for the periphery that is useless without the core/only supporting the core parts.

The fallback in the unlikely case that AI generated code would be illegal as such would be to revert to an old state, i.e. remove the new functionality, and rewrite the parts considered worthwhile by hand.
An option for e.g. new shell features stemming from vibe coding that are later on considered essential could be a follow-up implementation by a human programmer replacing it, just to be on the safe side.

Regarding the user manual:
- AI generated content is forbidden
- AI corrections are allowed
(What's the difference between AI proofreading compared to a regular spell checker?)

Information loss because of the prompts being sent to an external server is not an issue as the software is open source anyway.
