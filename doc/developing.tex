\chapter{Understanding and Extending GrGen.NET}\indexmain{internals}\indexmain{Developing GrGen.NET} \label{cha:developing}

This chapter describes the inner workings of \GrG~to allow external developers
\begin{itemize}
\item to understand how \GrG~works
\item esp. in order to extend it with new features
\footnote{which may be special extensions for a dedicated task, but also may be of general interest to other users}
\end{itemize}
It starts with a section on describing how to build \GrG, followed by a section giving an introduction into the generated code, then an introduction into the mechanism of search planning, ending with a section giving some details of the structure of, and the data flow in the \GrG-code generator.
Here we repeat some content from chapter \ref{sec:performance}, refining it with more detail.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{How to Build}\label{sub:building}\indexmain{building GrGen}

In case you want to build \GrG~on your own you should recall the system layout \ref{figsys}. 
The graph rewrite generator consists of a frontend written in Java and a backend written in C\#.
The frontend was extended and changed since its first version, but not replaced.
In contrast to the backend, which has seen multiple engines and versions: a MySQL database based version, a PSQL database based version, 
a C version executing a search plan with a virtual machine, a C\# engine executing code generated from a search plan and finally the current C\# engine version 2 capable of matching nested and subpatterns.
The frontend is available in the \texttt{frontend} subdirectory of the public mercurial repository at \texttt{https://bitbucket.org/eja/grgen}.
It can be built with the included \texttt{Makefile} on Linux or the \texttt{Makefile\_Cygwin} on Windows with the cygwin environment yielding a \texttt{grgen.jar}. 
Alternatively you may add the \texttt{de} subfolder and the jars in the \texttt{jars} subfolder to your favourite IDE, but then you must take care of the ANTLR parser generation pre-build-step on your own. 
The backend is available in the \texttt{engine-net-2} subdirectory. 
It contains a VisualStudio 2008 solution file containing projects for the \texttt{libGr}, the \texttt{lgspBackend} (libGr-Search-Plan-Backend) and the \texttt{GrShell}.
Before you can build the solution you must execute \texttt{./src/libGr/genparser.bat} and \texttt{./src/Gr\-Shell/genparser.bat}
to get the CSharpCC parsers for the rewrite sequences and the shell generated.
Under LINUX you may use \texttt{make\_linux.sh} to get a complete build.
To get the API examples generated you must execute \texttt{./genlibs.bat}.
The \texttt{doc} subdirectory contains the sources of the user manual, for building say \texttt{./build\_cygwin.sh grgen} on Windows in \texttt{cygwin-bash} or \texttt{./build grgen} on Linux in \texttt{bash}.
The \texttt{syntaxhighlighting} subdirectory contains syntax highlighting specifications for the GrGen-files for \texttt{Notepad++}, \texttt{vim}, and \texttt{Emacs}.

You can check the result of your build with the test suite we use to check against regressions.
It is split into syntactic tests in \texttt{frontend/test} checking that example model and rule files can get compiled by \texttt{grgen} (or not compiled, or only compiled emitting warnings) and the resulting code can get compiled by \texttt{csc}.
The tests get executed by calling \texttt{./test.sh} or \texttt{./testpar.sh} from \texttt{bash} or \texttt{cygwin-bash} (\texttt{testpar.sh} executes them in parallel speeding up execution on multi core systems considerably at the price of potential false positive reports); deviations from a gold standard are reported.
And semantic tests in \texttt{engine-net-2/tests} checking that executing example shell scripts on example models and rules yields the expected results. 
They get executed by calling \texttt{./test.sh}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The Generated Code}\indexmain{generated code}\label{sec:generatedcode}
In this section we'll have a look at what is generated by \GrG~of your specifications; firstly the model, secondly the rules, better matching their patterns, ending thirdly with an explanation of the matching of nested and subpatterns.

\subsection*{Internal Graph Representation}\indexmain{internal graph representation}\indexmain{ringlists}
The graph structure is maintained in an \texttt{LGSPGraph} built of \texttt{LGSPNode} and \texttt{LGSPEdge} objects, basically without type and attribute information.
The types defined in the model are realized by generated node and edge interfaces defining the user visible types and attributes, which are implemented by generated node and edge classes inheriting from and working like \texttt{LGSPNode}s and \texttt{LGSPEdge}s in the graph, additionally implementing the type and attribute bearing interfaces.

The nodes and edges are contained in a system of ringlists.
Top level there are the type ringlists, every node or edge is contained in the linked list of its specific type; the dummy head nodes or head edges serving as entry points into these structures are accessible from an array in the graph, storing as many heads as there are types.
Every node or edge contains a field \texttt{typeNext} giving the next element of the type.
These lists allow to quickly look up all elements from the graph bearing a certain type.
Figure \ref{figtyperinglists} gives an example for a graph with 3 node types, one having no instance nodes, one having only one instance node, and one having 5 instance nodes; the same holds for the edge types.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.65\textwidth]{fig/TypeRinglists}
  \caption{Example for type ringlists}
  \label{figtyperinglists}
\end{figure}

The connectedness information is stored in a ringlist containing the incoming edges and a ringlist containing the outgoing edges for every node object; the node object contains a field \texttt{inHead} referencing an arbitrary edge object of the incoming edges (or \texttt{null} of there is none) and a field \texttt{outHead} referencing an arbitrary edge object of the outgoing edges (or \texttt{null} if there is none).
These lists allow to quickly retrieve all incoming or all outgoing edges of a node.
The edge objects contain fields \texttt{source} and \texttt{target} referencing the source and the target node.
They give instant access to the source and target nodes of an edge.
Edges furthermore contain a field \texttt{inNext} to give the next edge in the incoming ringlist and a field \texttt{outNext} to give the next edge in the outgoing ringlist they are contained in.
All the 3 ringlists (type, in, out) are doubly linked (to allow for fast insertion and deletion), so for every \texttt{next} field there is also a \texttt{prev} field available.
The figure \ref{figincidenceexampleringlists} gives the ringlist implementation of the example graph depicted in figure \ref{figincidenceexample}. 

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.75\textwidth]{fig/IncidenceExample}
  \caption{Incidence example situation}
  \label{figincidenceexample}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.75\textwidth]{fig/IncidenceExampleRinglists}
  \caption{Ringlist implementation of incidence example}
  \label{figincidenceexampleringlists}
\end{figure}

In case attribute indices were declared, a balanced search tree (an AA-tree) is created for each of them.
The tree is maintained by event handlers that listen to graph element creation and deletion, but esp. for attribute assignment.
 
\subsection*{Pattern Matching and Search Programs}\indexmain{pattern matching implementation}\indexmain{search program}
The pattern of a rule (or test) is matched with a backtracking algorithm binding one pattern element after another to a graph element, checking if it fits to the already bound parts. If it does fit search continues trying to bind the next pattern element (or succeeds building the match object from all the elements bound if the last check succeeds), if it does not fit search continues with the next graph element; if all graph element candidates for this pattern element are exhausted, search backtracks to the previous decision point and continues there with the next element.
For every pattern to match a search program implementing this algorithm is generated, basically consisting of nested loops iterating the available graph elements for each pattern element and condition checking code continuing search with the next element to investigate.
Figure \ref{figpatterntosearchfirst} shows a pattern and a search program generated for it.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.7\textwidth]{fig/Pattern}
  \caption{Pattern to search}
  \label{figpatterntosearchfirst}
\end{figure}

\begin{csharp}
foreach(v1:A in graph) {
	foreach(e1 in outgoing(v1)) {
		if(type(e1)!=a) continue;
		v2 = e1.tgt;
		if(type(v2)!=B) continue;
		foreach(e3 in outgoing(v2)) {
			if(type(e3)!=b) continue;
			v3 = e3.tgt;
			if(type(v3)!=C) continue;
			foreach(e2 in outgoing(v3)) {
				if(type(e2)!=a) continue;
				if(e2.tgt!=v2) continue;
				// v1,e1,v2,e3,v3,v2 constitute a match
			} 
		}
	}
}
\end{csharp}

If a non-leaf-type (regarding inheritance hierarchy) is to be matched with a graph lookup (the outermost loop in the example), then an additional loop is used iterating all subtypes of the type of the pattern element.
If a pattern is given one or more parameters, search normally follows the graph structure by iterating the incoming or outgoing edges of a node or determining the source or target node of an edge, instead of looking up a type in the graph.
If a pattern consists of several unconnected components, several lookups are needed.
Undirected or arbitrary directed pattern edges are searched in both, the incoming and the outgoing ringlist; undirected edges are implemented by normal directed edges which can get matched in both directions.
Constraints which might cause an candidate to get rejected are the type of the element as shown in the example, structural connections to already bound elements and the isomorphy constraint.
Furthermore there are negative checking, independent checking, and attribute checking, which are normally depending on multiple elements.
Other matching operations are storage access, storage attribute access and storage mapping.

Compared to pattern matching which may need a long time, pattern rewriting is a very simple task following a simple sequence of node or edge operations, first creating all new nodes then edges, followed by an evaluation of the attributes, then deleting all edges and nodes, finally executing embedded sequences (see table \ref{table:executionorderrewriting} for more on this).

A notable performance optimization allowed by the graph model is \indexed{search state space stepping}: 
after a pattern was matched, the list heads of the type lookup ring lists, the incoming ring lists and the outgoing  ring lists are moved to the position of the matched entries with \texttt{MoveHeadAfter}, \texttt{MoveInHeadAfter} and \texttt{MoveOutHeadAfter}.
With this optimization the pattern matching during an iteration \texttt{r*} will start where the previous iteration step left of, saving the cost of iterating again through all the elements which failed in the previous iteration.

\vspace{1cm} %manual layout so the pushdown machine simulation starts on its own page

\subsection*{Pushdown Machine for Nested and Subpatterns}\indexmain{pushdown machine}\indexmain{stack machine}\label{pushdownmachine}
Every subpattern (as introduced in chapter \ref{cha:sub}) is handled with a search program corresponding to its pattern as introduced in the previous section. 
The interesting part is how the subpatterns used get combined, which happens with a $2+n$ pushdown machine.
It consists of a call stack, containing the subpattern instances found with the bound elements in the local variables of the search program frame, an open tasks stack containing the subpatterns to match (when a subpattern was matched its contained subpatterns are pushed to that open tasks stack, then the top of the stack gets processed), and $n$ result stacks containing the (partial) match object trees; for a normal rule application $n=1$, for an all-bracketed rule the number of matches is unbound.
A simulation of this machine, i.e. the matching process of a pattern using subpatterns is shown on the following pages.

Alternatives are handled like a subpattern with several possible patterns which are tried out, the first one matching is accepted.
Iterateds are handled like subpatterns whose tasks are not removed when they get matched, but only if matching failed or the maximum amount of matches was reached. In case of a failure the minimum required amount of matches is inspected, if the amount of found matches is larger or equal then matching partially succeeds and continues with the next open task (or plain succeeds if there are no open tasks left), otherwise matching of the given partial match fails causing matching to backtrack (to the previous decision point of influence).

The advantages of this design linearizing the pattern tree on the call stack are the rather low usage of heap memory, the ability to reuse the match programs for the patterns as introduced in the previous section, and the ability to find all matches (the $n$ in $2+n$ pushdown machine stands for the number of matches found).

Rewriting is carried out by a depth-first traversal of the match object tree, creating new elements before descending, evaluating attributes and deleting old elements before ascending. For each pattern piece matched the modification specified in the rewrite part is carried out, i.e. the overall rewrite gets combined from the rewrites of the pattern pieces (cf. table \ref{table:executionorderrewriting} for the order of rewriting).

The subpattern usage parameters are computed during matching from matched elements and call expressions (inherited attribution), LHS yielding is carried out after the match was found during match object building within yield statements (synthesized attribution), RHS yielding is carried out during match object tree rewriting within eval statements (left attribution, with a user defined left-relation).

In the following, an example run of the $2+n$ pushdown machine is given:

\vspace{2cm} % manual layout so the pushdown simulation starts on its own page

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{fig/Passungszustand1}
  \caption{1. Start state}
  \label{figmatchingstate1}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{fig/Passungszustand2}
  \caption{2. The terminal part of pattern A was matched}
  \label{figmatchingstate2}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{fig/Passungszustand3}
  \caption{3. The tasks for subpatterns B and C are pushed}
  \label{figmatchingstate3}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{fig/Passungszustand4}
  \caption{4. The task for B gets executed, the terminal part of B was matched}
  \label{figmatchingstate4}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{fig/Passungszustand5}
  \caption{5. The task for alternative D is pushed}
  \label{figmatchingstate5}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{fig/Passungszustand6}
  \caption{6. The task for D gets executed, D1 is tried, but matching fails}
  \label{figmatchingstate6}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{fig/Passungszustand7}
  \caption{7. The task for D gets executed, D2 was matched}
  \label{figmatchingstate7}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{fig/Passungszustand8}
  \caption{8. The task for C gets executed, C was matched, a match for the overall pattern was found, but is contained only on the call stack}
  \label{figmatchingstate8}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{fig/Passungszustand9}
  \caption{9. The match of C is popped from the call stack and pushed to the result stack}
  \label{figmatchingstate9}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{fig/Passungszustand10}
  \caption{10. The match of D2 is popped from the call stack and pushed to the result stack}
  \label{figmatchingstate10}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{fig/Passungszustand11}
  \caption{11. The match of B is popped from the call stack, D2 from the result stack is added, the combined match is pushed to the result stack}
  \label{figmatchingstate11}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{fig/Passungszustand12}
  \caption{12. The match of A is popped from the call stack, B and C from the result stack are added, now we got the combined match of the overall pattern}
  \label{figmatchingstate12}
\end{figure}


% belongs logically to following section
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.7\textwidth]{fig/Pattern}
  \caption{Pattern to search}
  \label{figpatterntosearch}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.7\textwidth]{fig/Graph}
  \caption{Host graph to search in}
  \label{figgraphtosearchin}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Search Planning in Code Generation}\indexmain{search plan}\indexmain{schedule}\indexmain{arborescence}\indexmain{search program}
\indexmain{host graph sensitive search plan driven graph pattern matching}\label{searchplanning}

In the previous section a search program for the pattern (repeated in figure \ref{figpatterntosearch}) was given.
It follows the schedule\\
\texttt{lkp(v1:A); out(v1,e1:a); tgt(e1,v2:B); out(v2,e3:b); tgt(e3,v3:C); out(v3,e2:a)}\\
A schedule is a more abstract version of a search program, with search operations \texttt{lkp} denoting node (or edge) lookup in the graph by iterating the type list, \texttt{out} iterating the outgoing edges of the given source node and \texttt{in} iterating the incoming edges of the given target node, \texttt{src} fetching the source from the given edge and \texttt{tgt} fetching the target from the given edge.
For some graphs it might work well, but for the graph given in figure \ref{figgraphtosearchin} is is a bad search plan. Why so can be seen in the search order sketched in figure \ref{figbadsearch}.
Due to the multiple outgoing edges of \texttt{v1} of which only one leads to a match it has to backtrack several times. A better search order would be one matching this edge from \texttt{v2} on in reverse direction; due to the graph model containing a list of outgoing and a list of incoming edges, each edge can be traversed in either direction.

For every pattern there are normally multiple search programs available,
each able to find all the matches which exist, but with vastly different performance characteristics.
In order to improve performance, \GrG~tries to prevent following graph structures splitting into breadth as given in this example or lookups on types which are available in high quantities, by first executing a planning phase to choose a good schedule. Due to the planning phase this schedule is chosen:\\
\texttt{lkp(v3:C); out(v3,e2:a); tgt(e2,v2:B); out(v2,e3:b); in(v2,e1:a); src(e1,v1:A)}\\
corresponding to the search order depicted in figure \ref{figgoodsearch} and the search program:

\begin{csharp}
foreach(v3:C in graph) {
	foreach(e2 in outgoing(v3)) {
		if(type(e2)!=a) continue;
		v2 = e2.tgt;
		if(type(v2)!=B) continue;
		foreach(e3 in outgoing(v2)) {
			if(type(e3)!=b) continue;
			if(e3.tgt!=v3) continue;
				foreach(e1 in incoming(v2)) {
				if(type(e1)!=a) continue;
				v1 = e1.src;
				if(type(v1)!=A) continue;
				buildMatchObjectOfPatternWith(v3,e2,v2,e3,e1,v1);
			} 
		}
	}
}
\end{csharp}

\vspace{15cm}

\begin{figure}[hptb]
  \centering
  \includegraphics[width=0.7\textwidth]{fig/GraphBad}
  \caption{Bad search order}
  \label{figbadsearch}
\end{figure}

\begin{figure}[hpbt]
  \centering
  \includegraphics[width=0.7\textwidth]{fig/GraphGood}
  \caption{Good search order}
  \label{figgoodsearch}
\end{figure}

The mechanism of search planning works by computing from the pattern graph a search plan graph.
A search plan graph is an edge-weighted graph, with nodes corresponding to the pattern elements -- both nodes and edges -- and edges corresponding to operations to match them, with weight attributes giving an estimated cost of the operation. 
A search plan graph contains an additional root node, with an outgoing edge to each other node defining a \texttt{lookup} operation. From plan nodes created for nodes there are \texttt{outgoing} and \texttt{incoming} operations leaving towards plan nodes created from edges, from plan nodes created for edges there are \texttt{source} and \texttt{target} operations leaving towards plan nodes created from nodes.
The cost is determined by analyzing the amount of splitting between adjacent nodes for every triple of $(node type, edge type, node type)$ in the graph -- called a \indexed{V-Structure} -- and by counting the number of elements of every node type or edge type.
In the plan graph a minimum spanning arborescence, i.e. directed tree is computed. 
The arborescence defining the matching operations causing least cost is then linearized into a schedule, which is a list of the search operations chosen as already introduced with the good and the bad schedules.
The details of search planning and some evaluation how well it works are given in \cite{searchplangrgen} and in \cite{BKG:07}.

\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}[bend angle=15]
    \tikzstyle{every node}=[minimum height=0.7cm,minimum width=0.9cm];

    \node[draw,ellipse,fill=white,inner sep=5pt] (root) at (6,0.5) {root};

    \node[draw,ellipse] (v1) at (0,5) {$\mathit{v1:A}$};
    \node[draw] (e1) at (3,5) {$e1:a$};
    \node[draw,ellipse] (v2) at (6,5) {$\mathit{v2:B}$};
    \node[draw] (e2) at (9.75,7) {$e2:a$};
    \node[draw] (e3) at (9.75,3.5) {$e3:b$};
    \node[draw,ellipse] (v3) at (13.5,5) {$\mathit{v3:C}$};

    \draw[-latex,bend left] (root.north) to node[near end, sloped, below] {$\mathsf{lkp}$/2} (v1.south);
    \draw[-latex] (root.north) -- (e1.south) node[near end, sloped, below] {$\mathsf{lkp}$/7};
    \draw[-latex] (root.north) -- (v2.south) node[midway, sloped, below] {$\mathsf{lkp}$/4};
    \draw[-latex,bend right] (root.north) to node[near end, sloped, below] {$\mathsf{lkp}$/7} (e2.south);
    \draw[-latex] (root.north) -- (e3.south) node[near end, sloped, below] {$\mathsf{lkp}$/2};
    \draw[-latex,bend right,line width = 2pt] (root.north) to node[near end, sloped, below] {$\mathsf{lkp}$/1} (v3.south);

    \draw[-latex,bend left] (v1) to node[midway, above] {$\mathsf{out}$/2.83} (e1);
    \draw[-latex,bend left,line width = 2pt] (e1) to node[midway, below] {$\mathsf{src}$/1} (v1);
    \draw[-latex,bend right] (e1) to node[midway, below] {$\mathsf{tgt}$/1} (v2);
    \draw[-latex,bend right,line width = 2pt] (v2) to node[midway, above] {$\mathsf{in}$/1} (e1);
    \draw[-latex,bend left] (v2) to node[midway, above] {$\mathsf{out}$/1} (e2);
    \draw[-latex,bend left,line width = 2pt] (e2) to node[midway, below] {$\mathsf{src}$/1} (v2);
    \draw[-latex,bend left,line width = 2pt] (v2) to node[midway, above] {$\mathsf{out}$/1} (e3);
    \draw[-latex,bend left] (e3) to node[midway, below] {$\mathsf{src}$/1} (v2);
    \draw[-latex,bend right] (e2) to node[midway, below] {$\mathsf{tgt}$/1} (v3);
    \draw[-latex,bend right,line width = 2pt] (v3) to node[midway, above] {$\mathsf{in}$/1} (e2);
    \draw[-latex,bend right] (e3) to node[midway, below] {$\mathsf{tgt}$/1} (v3);
    \draw[-latex,bend right] (v3) to node[midway, above] {$\mathsf{in}$/2} (e3);
  \end{tikzpicture}
  \caption{
  	The search plan graph for the pattern graph of Figure~\ref{figpatterntosearch} with estimated backtracking costs induced by the host graph of Figure~\ref{figgraphtosearchin}.
	The found minimum directed spanning tree is denoted by thick edges.
  }
  \label{fig:plan-graph}
\end{figure}


A search program is a lower abstraction version of a schedule.
Structurally it is a tree data structure reflecting the syntax tree of the code to generate (with list entries maybe containing further lists), as sketched in figure \ref{figsearchprogram}; in contrast to the schedule which is a simple list data structure.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.9\textwidth]{fig/SearchProgram}
  \caption{A simple Search Program}
  \label{figsearchprogram}
\end{figure}

It contains explicit instructions for isomorphy checking and connectedness checking, which are inserted after the schedule was determined along the exact sequence of instructions.
Connectedness checking can be seen in the good search program of the example in the check that the target of \texttt{e3} is indeed \texttt{v3};
a target matching operation \texttt{tgt(e3,v3:C)} is not used because \texttt{v3} was already matched by the lookup operation, and is already contained in the spanning tree.
Furthermore it contains exact locations where to continue at, which might be different than the directly preceding search operation (because that one does not define a choice point of influence).

A remark on isomorphy handling: As a consequence of the simple loop based graph element binding to pattern elements, without an explicit check all pattern elements could get matched completely homomorphically to each other (due to the loops starting with the same elements, the homomorphic matches \emph{are} normally the first to be found).
To ensure that two pattern elements are not bound to the same graph element, flags contained in the graph elements are set when a graph element is bound to a pattern variable and reset when the binding is given up again (one flag for each negative/independent nesting level, until the implementation defined limit of flags available in the graph elements is reached, then a list of dictionaries is used); the flags are checked then in the following, nested matching operations. An iso-check scheduling pass ensures that checks are only inserted if the elements must be isomorphic and their types do not already ensure that they can't get matched to the same elements.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The Code Generator}\indexmain{code generator}

\subsection{Frontend}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{fig/AblaufCodeerzeugungFrontend}
  \caption{Frontend Code Generation}
  \label{figfrontendcodegen}
\end{figure}

The frontend is spread over the directories \texttt{parser}, \texttt{ast}, \texttt{ir}, \texttt{be} and \texttt{util}, with their code being used from \texttt{Main.java}.

\subsubsection*{Syntax and Static Semantics}
The directory \texttt{parser} contains parser helpers like the symbol table and scopes and within the \texttt{antlr} subdirectory the ANTLR parser grammar of \GrG~in the file \texttt{Grgen.g}.
The semantic actions of the parser build an abstract syntax tree consisting of instances of the classes given in the directory \texttt{ast}, with the base class \texttt{BaseNode}.
The AST is operated upon in three passes, first resolving by \texttt{resolve} and \texttt{resolveLocal}, mainly replacing identifier nodes by their declaration nodes during a (largely) preorder walk.
Afterwards the AST is checked by \texttt{check} and \texttt{checkLocal} during a (largely) postorder walk for type and other semantic constraints.
Finally an intermediate representation is built from the abstract syntax tree by the \texttt{getIR} and \texttt{constructIR} methods.

\subsubsection*{Intermediate Representation}
The IR classes given in the \texttt{ir} folder can be seen as more lightweight AST classes; their name is often the same as for their corresponding AST classes, but without the \texttt{Node}-suffix which is appended to all AST classes.
The most interesting classes are \texttt{Rule} used for rules, alternative cases and iterateds, as well as \texttt{PatternGraph} used for all pattern graphs including negatives and independents;
several data flow analyses are contained in \texttt{PatternGraph}, some covering the nesting of patterns, some being even global.
A particularly interesting one is \texttt{ensure\-Directly\-Nesting\-Pattern\-Contains\-All\-Non\-Local\-Elements\-Of\-Nested\-Pattern} which ensures that, from a pattern which contains a certain entity the first time, up to every pattern that references this entity, all intermediate patterns contain that entity, too.

This is done in a recursive walk over the nested patterns in the IR-structure. 
Each pattern receives the set of already known elements as parameter,
before descending the elements available in the current pattern are added to the set of already known elements,
then recursive descent into the directly nested patterns follows handing down the already known elements.
On ascending elements are added to the current pattern if they are contained in a directly nested pattern, but not in the current pattern, although they are known in the current pattern.

This is done in the IR to keep the backends simple.
The IR classes are the input to the two backends of the frontend, as given in the folders \texttt{be/C} and \texttt{be/Csharp}.


\subsubsection*{Backends}

The directory \texttt{be/C} contains the code generator for the C based backend integrated into the IPD C compiler.
(The compiler transforms a C program into a graph and SSA based compiler intermediate representation named FIRM using libFirm (see \url{libfirm.org}, \cite{TBL:99}, \cite{Lin:02}) and further on to x86 machine code.)

The directory \texttt{be/Csharp} contains the code generator for the C\# based backend of \GrG. 
It generates the model source code \texttt{FooModel.cs} with the node and edge classes for a rule file named \texttt{Foo.grg}, 
and the intermediate rules source code \texttt{FooActions\_intermediate} with a description of the patterns to match, a description of the embedded graph rewrite sequences, and the rewriting code.
This is done in several recursive passes over the nesting structure of the patterns in the IR. 

The backend of the frontend does \emph{not} generate the complete rules source code with the matcher code or the code for the embedded rewrite sequences --- this is done by \texttt{grgen.exe} which only calls the \texttt{grgen.jar} of the frontend.
You may call the Java archive on your own to get a visualization of the model and rewrite rules from a \texttt{.vcg}-dump of the IR, cf. Note\ref{note:modelruledump}.


\subsubsection*{Model Generation}

The model generation code in \texttt{ModelGen} is rather straight forward:
\begin{enumerate}
	\item first code for the user defined enums is generated,
	\item then the node classes are generated,
	\item followed by the node model,
	\item then the the edge classes are generated,
	\item followed by the edge model,
	\item and finally the graph model is generated.
\end{enumerate}

\noindent For the nodes as well as for the edges three classes are generated:
\begin{enumerate}
	\item the first being the interface visible to the user, giving access to the attributes,
	\item the second being the implementation implementing the interface and inheriting from \texttt{LGSPNode} or \texttt{LGSPEdge},
	\item and the third being a type representation class inheriting from \texttt{NodeType} or \texttt{EdgeType} giving informations about the type and its attributes, used in the node/edge model and thus graph model.
\end{enumerate}


\subsubsection*{Rule Representation Pass}

The action code, better representation generation is implemented in \texttt{ActionsGen}, in the code called from \texttt{gen\-Subpattern} for the subpatterns and \texttt{gen\-Action} for the rules and tests on.

In a prerun from \texttt{gen\-Rule\-Or\-Subpattern\-Class\-Entities} on some needed entities are generated, e.g. type arrays for the allowed types of the pattern elements (the arrays are only filled if the base type was constrained), or indexing enums, which map the pattern element names to their index in the arrays of the matched host graph elements in the match objects of the generic match interface.

In the rule representation pass from \texttt{gen\-Rule\-Or\-Subpattern\-Init} on the subpattern- and rule representations of type \texttt{Matching\-Pattern} and \texttt{Rule\-Pattern} are generated, including the contained \texttt{Pattern\-Graph}-objects for the (nested) pattern graph(s), in a mutual recursion game of \texttt{gen\-Pattern\-Graph} and \texttt{gen\-Elements\-Required\-By\-Pattern\-Graph}.

The method \texttt{gen\-Elements\-Required\-By\-Pattern\-Graph} generates for a pattern graph its contained elements, the pattern nodes, the pattern edges, the used subpatterns as \texttt{Pattern\-Graph\-Embedding} members, the contained alternatives, and the iterateds; the representations of contained negative subpatterns and alternative cases get generated via \texttt{gen\-Pattern\-Graph} before the containing pattern. 

A graph element contained in pattern, but defined in a nesting pattern, is saved in the pattern as a reference to the element in the nesting pattern. 
The \texttt{Pattern\-Graph} in which it was used first is remembered in a \texttt{Point\-Of\-Definition}-membervariable.
The source and target nodes of edges are saved in the \texttt{Pattern\-Graph} in hash tables (so that an edge with an undefined target can receive a target in a nested pattern), source and target nodes are determined by ascending along the pattern nesting until a definition is found.

As all graph elements, including the ones of the nested patterns, are created flatly in the \texttt{initialize}-method of the \texttt{Matching\-Pattern}, name prefixes are needed to prevent name clashes; this is ensured by the parameter \texttt{path\-Prefix}.
Correct naming of already declared elements is ensured with a \texttt{already\-Defined\-Entity\-To\-Name}-hash-table.
The split into constructor and \texttt{initialize}-Methode ist needed because a recursive \texttt{Matching\-Pattern} must reference itself at construction.

Furthermore expressions trees for the attribute checks are generated, as well as local and global homomorphy tables for the nodes and the edges, defining which pattern elements may match the same host graph element (the global tables specify the homomorphy in between elements from the \texttt{Pattern\-Graph} of an alternative case or an iterated and an enclosing \texttt{Pattern\-Graph}).


\subsubsection*{Rewrite Code Pass}
In the rewrite pass the rewrite code gets generated, via \texttt{gen\-Modify} of \texttt{Modify\-Gen};
the nesting of negative or independent patterns does not need to be taken care of here as they don't possess rewrite parts.

For every pattern piece and its rewrite role (dependent rewriting, creation, deletion) are local rewrite methods generated, bringing at runtime the overall rewriting into effect by calling each other.
\texttt{Modify\-Generation\-State} holds the state during generation, while the \texttt{Modify\-Generation\-Task}s allow to give a left and right graph independent of the rewriting specified with the rule. The code for subpattern creation is generated by using an empty graph as left graph and the pattern graph as right graph, the code for subpattern deletion is generated by using the pattern graph as left graph and an empty graph as right graph, for a dependent rewrite the graphs from \texttt{IR::Rule} are simply referenced, for a test the pattern graph is used as left and right graph.
For alternatives and iterateds dispatching methods get generated calling the rewrite methods of the instances of the patterns matched.
Rewrite parameters are mapped to local parameters of the rewrite methods.

The core method of rewrite code generation \texttt{gen\-Modify\-Rule\-Or-Subrule} generates the rewriting of the given pattern and the calls to the rewrite methods of the nested patterns.
Because the rewrite methods of the nested patterns are placed flatly in their \texttt{Matching\-Pattern} or \texttt{Rule\-Pattern}, they receive their nesting path as name prefix, their role is distinguished by one of the name postfixs \texttt{Modify}, \texttt{Create} or \texttt{Delete}; for keeping a pattern unmodified obviously no methods are needed.

For embedded sequences \texttt{LGSPEmbeddedSequenceInfo} objects are generated, which do contain the sequence as string plus additional parameter informations, the real sequence code is generated in the backend.
For sequences embedded in alternatives, iterateds, or subpatterns additionally closure classes inheriting from \texttt{LGSPEmbeddedSequenceClosure} are generated.
They store the graph elements the pattern elements were bound to of the pattern containing the exec; the sequence execution function is then called from this closure, which is stored in a queue and executed from the top level rule.

Finally match classes are generated, for every pattern besides negative patterns an interface and a class implementing this interface.
The match classes are instantiated after a match of the corresponding pattern was found, giving a highly convenient and type safe interface to the matched entities to the user at API level.


\subsection{Backend}

The real matcher code is generated by the backend given in \texttt{engine-net-2}, in the \texttt{src/lgspBackend} subdirectory.
The processing is done in several passes in \texttt{lgsp\-Matcher\-Generator.cs}; the base data structure is the \texttt{PatternGraph}, resp. the nesting of the \texttt{PatternGraph}-objects, contained in the \texttt{RulePattern}-objects of the rules/tests or the \texttt{Matching\-Pattern}-objects of the subpatterns.

\pagebreak

\subsubsection*{1. Step}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{fig/AblaufCodeerzeugungBackend1}
  \caption{Backend Code Generation, step 1}
  \label{figbackendcodegen1}
\end{figure}

First the subpattern usages are inlined when \indexed{inlining} is assumed to be beneficial; this allows the programmer to extract common patterns into subpatterns increasing readability and modularity without loosing performance (but as of now only one level of inlining is supported, so beware of too much subpattern extraction, especially if the containing pattern would get disconnected by this). 
After (and partly before) this pattern rewriting the patterns and their relations are analyzed by the \texttt{PatternGraphAnalyzer} -- the analyze results are used for emitting better code later on (choosing more efficient but more limited implementations for language features which are not sufficient in the general case but are so for the specification at hand).
Then a \texttt{PlanGraph} is created from the \texttt{PatternGraph} and data from analyzing the host graph (for generating the initial matcher some default data given from the frontend is used).
A minimum spanning arborescence is computed defining a hopefully optimal set of operations for matching the pattern (the hopes are founded, see \cite{BKG:07}).
A \texttt{SearchPlanGraph} is built from the arborescence marked in the \texttt{PlanGraph} and used thereafter for scheduling the operations into a \texttt{ScheduledSearchPlan}, which gets completed by \texttt{Append\-Homomorphy\-Information} with isomorphy checking information.
The \texttt{ScheduledSearchPlan} is then stored in the \texttt{PatternGraph} it was computed from.


\subsubsection*{2. Step}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.5\textwidth]{fig/AblaufCodeerzeugungBackend2}
  \caption{Backend Code Generation, step 2}
  \label{figbackendcodegen2}
\end{figure}

In a second step the \texttt{Schedules} of the negative or independent \texttt{Pattern\-Graph}s are integrated into the \texttt{Schedule} of the enclosing \texttt{Pattern\-Graph}, by \texttt{Merge\-Negative\-And\-Independent\-Schedules\-Into\-Enclosing\-Schedules} in a recursive run over the nesting structure of the \texttt{Pattern\-Graph}s in the \texttt{Matching\-Pattern}s or \texttt{Rule\-Pattern}s.
Due to nested negative or independent graphs this may happen spanning several nesting levels;
the result is saved in the \texttt{Schedule\-Including\-Negatives\-And\-Independents} field of the non-negative/independent \texttt{Pattern\-Graph}s.


\subsubsection*{3. Step}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{fig/AblaufCodeerzeugungBackend3}
  \caption{Backend Code Generation, step 3}
  \label{figbackendcodegen3}
\end{figure}

Finally, in a third step code is generated by \texttt{Generate\-Matcher\-Source\-Code},
again in a recursive run over the nesting structure of the \texttt{Pattern\-Graph}s, 
using the \texttt{Schedule\-Including\-Negatives\-And\-Independents} stored in them. 

For each \texttt{Rule\-Pattern} an \texttt{Action}-class is generated, 
and for each \texttt{Matching\-Pattern} a \texttt{Subpattern\-Action}-class is generated.
Additionally for each alternative or iterated which is nested in a rule, test, or subpattern,
an \texttt{Alternative\-Action}-class or an \texttt{Iterated\-Action}-class are generated;
the alternative matcher will contain code for all alternative cases.
The real matching code is then generated into these classes.

The \texttt{SearchProgramBuilder} builds a \texttt{SearchProgram} tree data structure resembling the syntax tree of the code to generate out of the \texttt{Schedule\-Including\-Negatives\-And\-Independents} in the \texttt{Pattern\-Graph}s. 
In a further pass the \texttt{SearchProgram} is completed by the \texttt{Search\-Program\-Completer},
determining the locations to continue at when a check fails,
writing undo code for the effects which were applied from that point on to the current one.
Finally the C\# code gets generated by calling the \texttt{Emit} methods of the \texttt{SearchProgram}.
If you want to extends this code you may be interested in the \texttt{Dump} methods which dump the \texttt{SearchProgram} in an easier readable form into text files.

The \texttt{Subpattern\-Action}-classes do not only contain the matcher code, 
but are at the same time the tasks of the $2+n$ pushdown machine, which are pushed on the open tasks stack;
they contain the subpattern parameters as member variables.
The same holds for the \texttt{Alternative\-Action}- and \texttt{Iterated\-Action}-classes,
which do not hold parameters but entities from the nesting pattern they reference. 


\subsubsection*{Nested and Subpattern Matching}

The higher levels of code generation are in large parts independent from nested and subpattern matching and control of the $2+n$ pushdown machine.
Only on the level of search programs it becomes visible,  
with an \texttt{Initialize\-Subpattern\-Matching}-search program operation at the begin of a search program
and a \texttt{Finalize\-Subpattern\-Matching}-search program operation at the end of a search program;
but mainly with a call to \texttt{build\-Match\-Complete} when the end of the schedule is reached during search program building.
This corresponds to the innermost location in the search program,
the location at which during execution the local pattern was just found;
now the control code is inserted by \texttt{insert\-Push\-Subpattern\-Tasks},
pushing the tasks for the subpatterns used from this pattern, as well as alternatives and iterateds nested in this pattern.
To execute the open tasks a \texttt{Match\-Subpatterns} operation is inserted into the search program. 
Afterwards \texttt{insert\-Pop\-Subpattern\-Tasks} inserts the operations for cleaning the task stack,
\texttt{insert\-Check\-For\-Subpatterns\-Found} the operations to handle success and failure, 
and \texttt{insert\-Match\-Object\-Building} the code for maintaining the result stack.


\subsubsection*{Further Functionality}

The compiled graph rewrite sequences are handled by the \texttt{lgsp\-Sequence\-Checker} and \texttt{lgsp\-Sequence\-Generator} (together with the sequence parser from the libGr).
The \texttt{src/GrGen} subdirectory contains the \texttt{grgen.exe} compiler driver procedure.
The \texttt{src/libGr} subdirectory contains the libGr, offering the base interfaces a user of \GrG~sees on the API level for the model, the actions, the pattern graphs and the host graph.
The interfaces get implemented by code from the libGr search plan (lgsp) backend and by the generated code.
The libGr further offers a generic, name string and object based interface to access the named entities of the generated code.
In addition it offers the rewrite sequence parser which gets generated out of \texttt{SequenceParser.csc},
building the rewrite sequence AST from the classes in \texttt{Sequence.cs} further utilizing \texttt{SymbolTable.cs}.
The rewrite sequence classes contain a method \texttt{ApplyImpl(IGraph graph)} which executes them.
Finally the libGr offers several importers and exporters in the \texttt{src/libGr/IO} subfolder.

When GrGen rules are matched, as well as when the graph is changed, events are fired.
They allow to to display the matches and changes to the user in the debugger,
to record changes to a file for later playback, or record changes to a transaction undo log for later rollback, 
or to execute user code if event handlers are registered to them,
allowing users to build an event based graph rewriting mechanism on API level.
The graph delegates fired are given in \texttt{IGraph.cs}.
Graph events recording is implemented in \texttt{Recorder.cs} (replaying is normal \texttt{.grs} execution);
graph transaction handling is implemented in \texttt{lgspTransactionManager.cs}, with a list of undo items which know how to undo the effect on the graph which created them, which are purged on commit or executed on rollback.
Backtracking is implemented with nested transactions.
If you are changing the graph programmatically not using GrGen rules you have to fire the events on your own in case you want to use any of the mechanisms (graphical debugging, record and replay, transactions and backtracking, event based programming) above.

The \texttt{src/GrShell} subdirectory contains the GrShell application, which builds upon the generic interface (as it must be capable of coping with arbitrary used defined models and actions at runtime) and the sequence interpretation facilities offered by the libGr.
The command line parser of GrShell gets generated out of \texttt{GrShell.csc}, the shell implementation is given in \texttt{GrShellImpl.cs}.
Graphical debugging is offered by the \texttt{Debugger.cs} together with the \texttt{YCompClient.cs}, which implements the protocol available for controlling yComp, communicating with yComp over a tcp connection to localhost.

The \texttt{examples} subdirectory of \texttt{engine-net-2} contains a bunch of examples for using \GrG~with GrShell.
The \texttt{examples-api} subdirectory contains several examples of how to use \GrG~from the API.
In case you want to contribute and got further questions don't hesitate to contact us 
(via email to \texttt{grgen} at the host given by \texttt{ipd.info.uni-karlsruhe.de}).


